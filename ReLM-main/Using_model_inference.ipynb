{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輸入文章: 經查，原告起訴其前受雇於被告，因受到職業災害，主張被告應給付原領工資補償，被告則以原告另向勞動部勞工保險局（下稱勞保局）領取傷病給付，以及向新光產物保險股份有限公司（下稱新光產險公司）請領團體保險金，反訴求原告返還，核雙方所主張之權利，係基於同一事件所衍生之爭執，兩訴言詞辯論之資料可相互利用，且對於當事人間紛爭之一次解決及訴訟經濟有利，亦無不得提起反訴之情形，揆諸前揭說明，被告提起反訴，於法尚無不合，應予准許。\n",
      "修正後文章: 經查，原告起訴其前受雇於被告，因受到職業災害，主張被告應給付原領工資補償，被告則以原告另向勞動部勞工保險局（下稱勞保局）領取傷病給付，以及向新光產物保險股份有限公司（下稱新光產險公司）請領團體保險金，反請求原告返還，核雙方所主張之權利，係基於同一事件所所生之爭執，兩訴言詞辯論之資料可相互利用，且對於當事人間紛爭之一次解決及訴訟經濟有利，亦無不得提起反訴之情形，揆諸前揭說明，被告提起反訴，於法尚無不合，應予准許。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, BertForMaskedLM\n",
    "from run_relm import PTuningWrapper\n",
    "\n",
    "def load_model_and_tokenizer(model_path, pretrained_model_path, prompt_length=1):\n",
    "    \"\"\"載入模型與 tokenizer\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(pretrained_model_path)\n",
    "    base_model = BertForMaskedLM.from_pretrained(pretrained_model_path)\n",
    "    model = PTuningWrapper(base_model, prompt_length)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cpu\"), weights_only=True))\n",
    "    model.eval()\n",
    "    return tokenizer, model\n",
    "\n",
    "def predict_sentence(sentence, tokenizer, model, prompt_length):\n",
    "    \"\"\"對單句進行模型推論與修正，處理長句分段\"\"\"\n",
    "    max_len = 128 - 2  # 扣除 [CLS] 和 [SEP] 的長度\n",
    "    tokenized = tokenizer(sentence, return_offsets_mapping=True, add_special_tokens=False)\n",
    "    input_ids = tokenized[\"input_ids\"]\n",
    "\n",
    "    # 將長句分段處理\n",
    "    segments = [input_ids[i:i + max_len] for i in range(0, len(input_ids), max_len)]\n",
    "    corrected_text = \"\"\n",
    "\n",
    "    for segment in segments:\n",
    "        inputs = tokenizer.decode(segment, skip_special_tokens=True)\n",
    "        inputs = tokenizer(inputs, return_tensors=\"pt\", max_length=128, padding=\"max_length\", truncation=True)\n",
    "        segment_ids = inputs[\"input_ids\"]\n",
    "\n",
    "        # 生成 prompt_mask\n",
    "        prompt_mask = torch.zeros_like(segment_ids)\n",
    "        prompt_mask[:, :2 * prompt_length] = 1\n",
    "\n",
    "        # 模型推論\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=segment_ids, \n",
    "                            attention_mask=inputs[\"attention_mask\"], \n",
    "                            prompt_mask=prompt_mask,  \n",
    "                            apply_prompt=True)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "        # 解碼並清理 token\n",
    "        predicted_tokens = tokenizer.convert_ids_to_tokens(predictions[0])\n",
    "        input_tokens = tokenizer.convert_ids_to_tokens(segment_ids[0])\n",
    "\n",
    "        corrected_text += clean_tokens_with_numbers(input_tokens[1:], predicted_tokens[1:])\n",
    "\n",
    "    return corrected_text\n",
    "\n",
    "def clean_tokens_with_numbers(input_tokens, predicted_tokens):\n",
    "    \"\"\"清理預測的 tokens，保留數字不變，處理 ## 拼接，排除中文數字修改，跳過 UNK token\"\"\"\n",
    "    chinese_numerals = set(\"零一二三四五六七八九十百千萬億\")\n",
    "    clean_text = \"\"\n",
    "    for input_token, predicted_token in zip(input_tokens, predicted_tokens):\n",
    "        if input_token in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]:\n",
    "            continue\n",
    "        # 跳過 UNK token\n",
    "        if predicted_token == \"[UNK]\":\n",
    "            clean_text += input_token\n",
    "        # 保留數字與中文數字不變\n",
    "        elif input_token in chinese_numerals or input_token.isdigit():\n",
    "            clean_text += input_token\n",
    "        elif predicted_token.startswith(\"##\"):\n",
    "            clean_text += predicted_token[2:]\n",
    "        else:\n",
    "            clean_text += predicted_token\n",
    "    return clean_text\n",
    "\n",
    "def process_article(article_text, tokenizer, model, prompt_length=1):\n",
    "    \"\"\"將文章分句並進行修正，輸出完整修正後的文章\"\"\"\n",
    "    sentences = [s + \"。\" for s in article_text.split(\"。\") if s]  # 分句並保留句號\n",
    "    corrected_sentences = []\n",
    "    for sentence in sentences:\n",
    "        corrected_sentence = predict_sentence(sentence, tokenizer, model, prompt_length)\n",
    "        corrected_sentences.append(corrected_sentence)\n",
    "    return \"\".join(corrected_sentences)\n",
    "\n",
    "# === 主程式 ===\n",
    "if __name__ == \"__main__\":\n",
    "    # 設定路徑\n",
    "    model_path = \"./model/Judgement_271K_filtered/step-10200_f1-76.67.bin\"  # 替換成你的模型權重路徑\n",
    "    pretrained_model_path = \"bert-base-chinese\"\n",
    "    prompt_length = 1\n",
    "\n",
    "    # 載入模型與 tokenizer\n",
    "    tokenizer, model = load_model_and_tokenizer(model_path, pretrained_model_path, prompt_length)\n",
    "\n",
    "    # 輸入文章字串\n",
    "    article_text = \"經查，原告起訴其前受雇於被告，因受到職業災害，主張被告應給付原領工資補償，被告則以原告另向勞動部勞工保險局（下稱勞保局）領取傷病給付，以及向新光產物保險股份有限公司（下稱新光產險公司）請領團體保險金，反訴求原告返還，核雙方所主張之權利，係基於同一事件所衍生之爭執，兩訴言詞辯論之資料可相互利用，且對於當事人間紛爭之一次解決及訴訟經濟有利，亦無不得提起反訴之情形，揆諸前揭說明，被告提起反訴，於法尚無不合，應予准許。\"\n",
    "    \n",
    "    # 修正文章\n",
    "    corrected_article = process_article(article_text, tokenizer, model, prompt_length)\n",
    "    \n",
    "    # 輸出結果\n",
    "    print(\"輸入文章:\", article_text)\n",
    "    print(\"修正後文章:\", corrected_article)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
